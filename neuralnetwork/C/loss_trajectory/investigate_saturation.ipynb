{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a48422f-897b-48b0-8bc2-4a42f8a6563c",
   "metadata": {},
   "source": [
    "I use this notebook to investigate why the uncertainty saturates when we extrapolate too far, as illustrated by our energy cold curve predictions.\n",
    "An argument is that because we extrapolate too far, the output of the activation function saturates.\n",
    "Especially since the activation function that I use, which is the tanh function, maps the entire real line to values between -1 and 1.\n",
    "Additionally, this analysis should be paired with the distribution of the weights and bias of the output layer.\n",
    "\n",
    "Note: The output of the last activation function (i.e., input to the last layer) needs to be generated first, for example using `investigate_saturation_generate.py` Python script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108c0c13-3fd2-4f43-acf4-e2691df68439",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a38266-b553-47c0-9366-a5d90f9a3eb6",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435b2499-949f-4dfd-9006-0db1ee16eea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_DIR = Path().resolve()\n",
    "ROOT_DIR = FILE_DIR.parent\n",
    "SETTINGS_DIR = ROOT_DIR / \"settings\"\n",
    "structure = \"diamond\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcf0302-3670-4ac7-8ab1-0a7370e6ab88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read setting file and set necessary directories and variables\n",
    "settings_path = SETTINGS_DIR / \"settings0.json\"\n",
    "with open(settings_path, \"r\") as f:\n",
    "    settings = json.load(f)\n",
    "Nnodes = settings[\"architecture\"][\"Nnodes\"]\n",
    "RES_DIR = FILE_DIR / \"results\" / settings_path.with_suffix(\"\").name\n",
    "nsamples = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806ad0ff-d767-4425-9611-d57ca3f4d96d",
   "metadata": {},
   "source": [
    "# Last layer weights and bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbcac21-821e-4ad6-b114-8a79da375667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load parameters\n",
    "last_layer_params = []\n",
    "for ii in tqdm(range(nsamples)):\n",
    "    sample_dir = RES_DIR / f\"{ii:03d}\"\n",
    "    last_layer_params.append(np.load(sample_dir / \"last_params.npy\")[-(Nnodes[-1]+1):])\n",
    "last_layer_params = np.vstack(last_layer_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d77b70-92de-4a64-a7d2-0faa6c52addd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistics\n",
    "llp_mean = np.mean(last_layer_params, axis=0)\n",
    "llp_std = np.std(last_layer_params, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9550cf4-635d-4935-a638-909d26e64e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots\n",
    "plt.figure()\n",
    "plt.plot(range(len(llp_mean) - 1), llp_mean[:-1], lw=1, c=\"k\", zorder=10, label=\"Mean\")\n",
    "plt.fill_between(range(len(llp_std)), -llp_std, llp_std, alpha=0.5, label=\"Stdev\")\n",
    "plt.text(0.5, max(llp_std), f\"Bias mean: {llp_mean[-1]:.3f}\", fontsize=12, color=\"red\")\n",
    "plt.xlabel(\"Parameter index\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96df07a2-483e-433b-9642-43a18f1c553c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for ii, ens in enumerate(last_layer_params.T):\n",
    "#     plt.figure()\n",
    "#     plt.title(f\"Parameter index {ii}\")\n",
    "#     plt.hist(ens, density=True, bins=10)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3f17f8-5c03-4998-af57-6b2baa6e6c2f",
   "metadata": {},
   "source": [
    "# Last activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ff715b-7520-469d-8961-d72c6be3d7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "output_activation = []\n",
    "for ii in tqdm(range(nsamples)):\n",
    "    sample_dir = RES_DIR / f\"{ii:03d}\"\n",
    "    with open(sample_dir / f\"input_last_layer_{structure}.pkl\", \"rb\") as f:\n",
    "        output = pickle.load(f)\n",
    "    try:\n",
    "        output_activation.append(np.swapaxes(np.array(output), 0, 1))\n",
    "    except:\n",
    "        print(ii)\n",
    "        continue\n",
    "output_activation = np.concatenate(output_activation, axis=0)\n",
    "nlat_params = output_activation.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a8b694-4f02-47c6-af5c-65be67bcb959",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_activation_mean = np.mean(output_activation, axis=0)\n",
    "output_activation_std = np.std(output_activation, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382b2d6f-783e-4512-a6a0-e89131e70b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for val in output_activation_std.T:\n",
    "    plt.plot(val)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02bb210-a9a4-44a2-b334-fbf740a89d69",
   "metadata": {},
   "source": [
    "## Validation\n",
    "\n",
    "If I extracted the input of the last layer correctly, I should be able to reconstruct the prediction mean and standard deviation from a simple linear mapping of these input values and the weights and bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f5b35c-4fbe-4911-8895-e9f7d45bd2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_validation = np.empty((nsamples, nlat_params))\n",
    "for ii in range(nsamples):\n",
    "    for jj in range(nlat_params):\n",
    "        output_validation[ii, jj] = sum(output_activation[2*ii:2*(ii+1), jj] @ last_layer_params[ii, :-1]) + last_layer_params[ii, -1]\n",
    "\n",
    "val_mean = np.mean(output_validation, axis=0)\n",
    "val_std = np.std(output_validation, axis=0)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(range(nlat_params), val_mean)\n",
    "plt.ylabel(\"Mean\")\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(range(nlat_params), val_std)\n",
    "plt.ylabel(\"Standard deviation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3c728a-52fc-4c46-a939-46999177aaf0",
   "metadata": {},
   "source": [
    "## Comparative analysis\n",
    "\n",
    "I don't want to look at all lattice parameter.\n",
    "Here, I only pick several locations that I think cover the interesting regime, such as: far left, left uncertainty peak, DFT minimum, right uncertainty peak, and far right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a451071-6d96-4895-9268-32d26c00b573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These indices point to the 6 lattice parameters that I am interested in\n",
    "if structure == \"diamond\":\n",
    "    aidx = [0, 4, 7, 9, 17, 20]\n",
    "elif structure == \"graphene\":\n",
    "    aidx = [0, 10, 15, 19, 25, 38, 42, 49]\n",
    "elif structure == \"graphite\":\n",
    "    aidx = [0, 6, 15, 19, 25, 38, 42, 49]\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(range(nlat_params), val_std, c=\"k\")\n",
    "for ai in aidx:\n",
    "    plt.axvline(ai, ls=\"--\", lw=1)\n",
    "plt.ylabel(\"Standard deviation\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9eca68-6322-45ae-a395-67025398db10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot the distributions of input and parameters of the last layer\n",
    "for ii in range(output_activation.shape[-1]):\n",
    "    fig, axes = plt.subplots(1, len(aidx) + 1, figsize=(4.8 * (len(aidx) + 1), 4.8))\n",
    "    fig.suptitle(f\"Index: {ii}, Weights = {llp_mean[ii]:0.4f} $\\pm$ {llp_std[ii]:0.5}\")\n",
    "    ylim_max = []\n",
    "    for jj, ai in enumerate(aidx):\n",
    "        ax = axes[jj]\n",
    "        ax.hist(output_activation[:, ai, ii], density=True, bins=10)\n",
    "        if jj == 0:\n",
    "            ax.set_ylabel(\"Density input to last layer\")\n",
    "        else:\n",
    "            ax.set_yticklabels([])\n",
    "        # ylim to simulate sharey=True\n",
    "        ylim_max.append(ax.get_ylim()[1])\n",
    "    for jj in range(len(aidx)):\n",
    "        ax = axes[jj]\n",
    "        ax.set_ylim(0, 1.1 * max(ylim_max))\n",
    "    # Add the plot of distribution of weights\n",
    "    ax = axes[-1]\n",
    "    ax.hist(last_layer_params[:, ii], density=True, bins=10)\n",
    "    ax.yaxis.tick_right()  # Moves tick labels to the right\n",
    "    ax.yaxis.set_ticks_position(\"right\")  # Moves ticks to the right\n",
    "    ax.yaxis.set_label_position(\"right\")  # Moves label to the right\n",
    "    ax.set_ylabel(\"Density of last layer parameter\")  # Set axis label\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad47601-7256-4521-9313-e6f5580dbffe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
